{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37618895",
   "metadata": {},
   "source": [
    "![../docs/images/banner.png](../docs/images/banner.png)\n",
    "\n",
    "\n",
    "# [Contact Us](mailto:info@inverted.ai) for the server ip address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install iai-client\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f24ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iai_client.utils import Res, SensorSettings, Resolution, PyGameWindow, ClientSideBoundingBoxes\n",
    "from iai_client.interface import IAIEnv\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "import argparse\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_res = Res.MD\n",
    "scale = 1\n",
    "\n",
    "sensors_dict = {\n",
    "        'top-cam': {\n",
    "            'sensor_type': 'camera',\n",
    "            'camera_type': 'rgb-camera',\n",
    "            'bounding_box': True,\n",
    "            'track_actor_types': SensorSettings.Available_Tracked_Actors,\n",
    "            'show_bounding_boxes': True,\n",
    "            'world_sensor': False,\n",
    "            'resolution': def_res,\n",
    "            'location': SensorSettings.Location(x=0.0, z=80.0, y=0.0),\n",
    "            'rotation': SensorSettings.Rotation(yaw=90.0, pitch=-90.0, roll=0.0),\n",
    "            },\n",
    "            'front-cam-seg': {\n",
    "            'sensor_type': 'camera',\n",
    "            'camera_type': 'segmentation',\n",
    "            'bounding_box': True,\n",
    "            'track_actor_types': SensorSettings.Available_Tracked_Actors,\n",
    "            'show_bounding_boxes': True,\n",
    "            'world_sensor': False,\n",
    "            'resolution': def_res,\n",
    "            'location': SensorSettings.Location(x=0, z=2.8, y=0),\n",
    "            'rotation': SensorSettings.Rotation(yaw=0, roll=0, pitch=0),\n",
    "            'radius': 20,\n",
    "            },\n",
    "            'side-cam':{\n",
    "            'sensor_type': 'camera',\n",
    "            'camera_type': 'rgb-camera',\n",
    "            'bounding_box': False,\n",
    "            # 'track_actor_types': 'all', #Actors, # or 'all'\n",
    "            'track_actor_types': SensorSettings.Available_Tracked_Actors,\n",
    "            'show_bounding_boxes': False,\n",
    "            'world_sensor': False,\n",
    "            'resolution': def_res,\n",
    "            'location': SensorSettings.Location(x=0, z=2.8, y=0),\n",
    "            'rotation': SensorSettings.Rotation(yaw=90, roll=0, pitch=0),\n",
    "            'fov': 90.0,\n",
    "            },\n",
    "        'boundingbox_side_cam': {\n",
    "            'sensor_type': 'boundingbox',\n",
    "            'track_actor_types': SensorSettings.Available_Tracked_Actors,  # or 'all'\n",
    "            'world_sensor': False, # if True returns the coordinates in the global frame of reference\n",
    "            'attach_to_actor': 'side-cam',\n",
    "            'radius': 20,\n",
    "            'occlusion': True,\n",
    "            },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00814d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "IAIEnv.add_config(parser)\n",
    "config = parser.parse_args(['--client_id', 'mycompany'])\n",
    "server_ip = input('Enter server IP:')\n",
    "config.zmq_server_address = f\"{server_ip}:5555\"\n",
    "env = IAIEnv(config)\n",
    "world_parameters = dict(carlatown='Town04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.set_scenario('egodriving', world_parameters=world_parameters, sensors=sensors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_render(obs):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.cla()\n",
    "    ax.axis('off')\n",
    "    plt.imshow(obs['front_image'].astype(int))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    plt.imshow(obs['birdview_image'].astype(int))\n",
    "    plt.show()\n",
    "pygame.init()\n",
    "\n",
    "dim = (scale*def_res.width, scale*def_res.height)\n",
    "width = np.sum([sensors_dict[sns]['resolution'].width*scale for sns in sensors_dict if sensors_dict[sns]['sensor_type']=='camera'])\n",
    "height = np.max([sensors_dict[sns]['resolution'].height*scale for sns in sensors_dict if sensors_dict[sns]['sensor_type']=='camera'])\n",
    "full_res = Resolution(width, height)\n",
    "main_display = PyGameWindow(full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [0.0, 0.0]\n",
    "obs, reward, done, info = env.step(action)\n",
    "disp_img = np.concatenate(list(cv2.resize(obs['sensor_data'][name]['image'], dim, interpolation = cv2.INTER_AREA) for name in sensors_dict if 'image' in obs['sensor_data'][name].keys()), axis=1)\n",
    "main_display.render(disp_img)\n",
    "pygame.display.update()\n",
    "jupyter_render(obs)\n",
    "rem_self = 0\n",
    "howlong = 0\n",
    "while not done:\n",
    "    prev_action = obs['prev_action']\n",
    "    if rem_self < howlong:\n",
    "        action = info['expert_action']\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rem_self += 1\n",
    "    else:\n",
    "        cmd = input('Enter Steering:')\n",
    "        if cmd == 'reset':\n",
    "            obs = env.reset()\n",
    "            jupyter_render(obs)\n",
    "        elif cmd == 'init':\n",
    "            obs = env.set_scenario('egodriving', world_parameters=world_parameters, sensors=sensors_dict)\n",
    "        elif cmd == 'end':\n",
    "            print(env.end_simulation())\n",
    "            break\n",
    "        elif cmd == 'self':\n",
    "            howlong = int(input('How many steps:'))\n",
    "            rem_self = 0\n",
    "        else:\n",
    "            angle = float(cmd)\n",
    "            acceleration = float(input('Enter Acceleration:'))\n",
    "            action = (acceleration, angle)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "    clear_output(wait=True)\n",
    "    jupyter_render(obs)\n",
    "    for name in sensors_dict:\n",
    "        if (sensors_dict[name]['sensor_type'] == 'boundingbox'):\n",
    "            if (sensors_dict[name]['attach_to_actor'] != 'ego'):\n",
    "                attached_sensor = sensors_dict[name]['attach_to_actor']\n",
    "                bb2d = ClientSideBoundingBoxes.get_2d_bbox(obs['sensor_data'][name]['bounding_boxes'], sensors_dict[attached_sensor]['location'], sensors_dict[attached_sensor]['rotation'], sensors_dict[attached_sensor]['fov'], sensors_dict[attached_sensor]['resolution'], obs['compact_vector'][:3], obs['compact_vector'][3:6], coordinate_system='attached_sensor', occlusion=True)\n",
    "                img = obs['sensor_data'][attached_sensor]['image']\n",
    "                obs['sensor_data'][attached_sensor]['image'] = ClientSideBoundingBoxes.draw_bounding_boxes_on_array(img, bb2d,  draw2d=True, occlusion=True)\n",
    "\n",
    "    disp_img = np.concatenate(list(cv2.resize(obs['sensor_data'][name]['image'], dim, interpolation = cv2.INTER_AREA) for name in sensors_dict if 'image' in obs['sensor_data'][name].keys()), axis=1)\n",
    "    main_display.render(disp_img)\n",
    "    pygame.display.update()\n",
    "print(f'Episode Done, Reward:{reward}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.end_simulation())\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "name": "usr-demo.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
